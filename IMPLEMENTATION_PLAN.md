# ComplyFormAI - Implementation Plan for Production Readiness

## Overview
This document outlines a phased approach to transform the current MVP into a production-ready system. Estimated timeline: 3-4 weeks.

---

## Phase 1: Critical Security & Bug Fixes (Week 1) üö®

### Priority 1.1: Fix 404 Error & Verify API Endpoints
**Status**: IMMEDIATE
**Time**: 30 minutes

**Issue**: User reported 404 error when accessing `/api/vi/organizations`
**Root Cause**: Typo in URL - should be `/api/v1/organizations` (v1, not vi)

**Action Items**:
- ‚úÖ Verify correct URL: `http://localhost:8000/api/v1/organizations`
- ‚úÖ Test all endpoints listed in API_REFERENCE.md
- ‚úÖ Update any client code with correct URLs

**Testing Commands**:
```bash
# Test organizations endpoint
curl http://localhost:8000/api/v1/organizations

# Test health check
curl http://localhost:8000/health

# View all available endpoints
curl http://localhost:8000/docs
```

---

### Priority 1.2: Remove Hardcoded Credentials
**Status**: CRITICAL
**Time**: 1-2 hours

**Current Issue**: Database password hardcoded in `app/config.py:6`

**Implementation Steps**:

1. **Create `.env.example` template**:
```env
# Database Configuration
DATABASE_URL=postgresql://username:password@localhost:5432/ComplyFormAI
DATABASE_POOL_SIZE=5
DATABASE_MAX_OVERFLOW=10

# Application Settings
DEBUG=false
SECRET_KEY=your-secret-key-here-generate-with-openssl
API_V1_PREFIX=/api/v1
PROJECT_NAME=ComplyForm API

# CORS Settings
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:5173

# Security
ACCESS_TOKEN_EXPIRE_MINUTES=30
ALGORITHM=HS256
```

2. **Update `app/config.py`**:
```python
from pydantic_settings import BaseSettings
from typing import List
import os
import secrets

class Settings(BaseSettings):
    # Database - NO DEFAULTS for sensitive data
    DATABASE_URL: str
    DATABASE_POOL_SIZE: int = 5
    DATABASE_MAX_OVERFLOW: int = 10

    # Application
    DEBUG: bool = False
    API_V1_PREFIX: str = "/api/v1"
    PROJECT_NAME: str = "ComplyForm API"

    # Security
    SECRET_KEY: str = secrets.token_urlsafe(32)  # Generate if not provided
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30
    ALGORITHM: str = "HS256"

    # CORS
    ALLOWED_ORIGINS: List[str] = ["http://localhost:3000"]

    class Config:
        env_file = ".env"
        env_file_encoding = 'utf-8'
        case_sensitive = True
        extra = "ignore"

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        if not self.DATABASE_URL:
            raise ValueError("DATABASE_URL must be set in environment or .env file")

settings = Settings()
```

3. **Create `.env` file** (add to `.gitignore`):
```bash
# Generate secret key
python -c "import secrets; print(f'SECRET_KEY={secrets.token_urlsafe(32)}')" >> .env

# Add database URL
echo "DATABASE_URL=postgresql://postgres:admin@localhost:5432/ComplyFormAI" >> .env
echo "DEBUG=true" >> .env
```

4. **Update `.gitignore`**:
```
.env
.env.local
.env.*.local
__pycache__/
*.pyc
venv/
```

**Files to modify**:
- `app/config.py`
- Create: `.env.example`
- Create: `.env` (not committed)
- Update: `.gitignore`

---

### Priority 1.3: Add Authentication & Authorization
**Status**: CRITICAL
**Time**: 6-8 hours

**Implementation Steps**:

1. **Install dependencies**:
```bash
pip install python-jose[cryptography]==3.3.0
pip install passlib[bcrypt]==1.7.4
pip install python-multipart==0.0.6
```

2. **Create `app/models/user.py`**:
```python
from sqlalchemy import Column, String, Boolean, DateTime
from sqlalchemy.dialects.postgresql import UUID
from datetime import datetime
import uuid
from app.database import Base

class User(Base):
    __tablename__ = "users"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    email = Column(String(255), unique=True, nullable=False, index=True)
    hashed_password = Column(String(255), nullable=False)
    full_name = Column(String(255))
    is_active = Column(Boolean, default=True)
    is_superuser = Column(Boolean, default=False)
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
```

3. **Create `app/core/security.py`**:
```python
from datetime import datetime, timedelta
from typing import Optional
from jose import JWTError, jwt
from passlib.context import CryptContext
from app.config import settings

pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

def verify_password(plain_password: str, hashed_password: str) -> bool:
    return pwd_context.verify(plain_password, hashed_password)

def get_password_hash(password: str) -> str:
    return pwd_context.hash(password)

def create_access_token(data: dict, expires_delta: Optional[timedelta] = None):
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=15)
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, settings.SECRET_KEY, algorithm=settings.ALGORITHM)
    return encoded_jwt

def decode_access_token(token: str):
    try:
        payload = jwt.decode(token, settings.SECRET_KEY, algorithms=[settings.ALGORITHM])
        return payload
    except JWTError:
        return None
```

4. **Create `app/core/deps.py`** (Dependencies):
```python
from fastapi import Depends, HTTPException, status
from fastapi.security import OAuth2PasswordBearer
from sqlalchemy.orm import Session
from jose import JWTError, jwt
from app.database import get_db
from app.models.user import User
from app.config import settings

oauth2_scheme = OAuth2PasswordBearer(tokenUrl=f"{settings.API_V1_PREFIX}/auth/login")

async def get_current_user(
    token: str = Depends(oauth2_scheme),
    db: Session = Depends(get_db)
) -> User:
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Could not validate credentials",
        headers={"WWW-Authenticate": "Bearer"},
    )
    try:
        payload = jwt.decode(token, settings.SECRET_KEY, algorithms=[settings.ALGORITHM])
        email: str = payload.get("sub")
        if email is None:
            raise credentials_exception
    except JWTError:
        raise credentials_exception

    user = db.query(User).filter(User.email == email).first()
    if user is None:
        raise credentials_exception
    return user

async def get_current_active_user(
    current_user: User = Depends(get_current_user)
) -> User:
    if not current_user.is_active:
        raise HTTPException(status_code=400, detail="Inactive user")
    return current_user
```

5. **Create `app/routes/auth.py`**:
```python
from datetime import timedelta
from fastapi import APIRouter, Depends, HTTPException, status
from fastapi.security import OAuth2PasswordRequestForm
from sqlalchemy.orm import Session
from app.database import get_db
from app.core.security import verify_password, create_access_token, get_password_hash
from app.models.user import User
from app.schemas.auth import Token, UserCreate, UserResponse
from app.config import settings

router = APIRouter(prefix="/auth", tags=["authentication"])

@router.post("/register", response_model=UserResponse, status_code=status.HTTP_201_CREATED)
def register(user_data: UserCreate, db: Session = Depends(get_db)):
    """Register a new user"""
    # Check if user exists
    existing_user = db.query(User).filter(User.email == user_data.email).first()
    if existing_user:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Email already registered"
        )

    # Create new user
    user = User(
        email=user_data.email,
        hashed_password=get_password_hash(user_data.password),
        full_name=user_data.full_name
    )
    db.add(user)
    db.commit()
    db.refresh(user)
    return user

@router.post("/login", response_model=Token)
def login(
    form_data: OAuth2PasswordRequestForm = Depends(),
    db: Session = Depends(get_db)
):
    """Login and get access token"""
    user = db.query(User).filter(User.email == form_data.username).first()
    if not user or not verify_password(form_data.password, user.hashed_password):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Incorrect email or password",
            headers={"WWW-Authenticate": "Bearer"},
        )

    if not user.is_active:
        raise HTTPException(status_code=400, detail="Inactive user")

    access_token_expires = timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)
    access_token = create_access_token(
        data={"sub": user.email}, expires_delta=access_token_expires
    )
    return {"access_token": access_token, "token_type": "bearer"}

@router.get("/me", response_model=UserResponse)
def read_users_me(current_user: User = Depends(get_current_active_user)):
    """Get current user"""
    return current_user
```

6. **Create schemas in `app/schemas/auth.py`**:
```python
from pydantic import BaseModel, EmailStr
from uuid import UUID
from datetime import datetime

class Token(BaseModel):
    access_token: str
    token_type: str

class TokenData(BaseModel):
    email: str | None = None

class UserCreate(BaseModel):
    email: EmailStr
    password: str
    full_name: str | None = None

class UserResponse(BaseModel):
    id: UUID
    email: EmailStr
    full_name: str | None
    is_active: bool
    created_at: datetime

    class Config:
        from_attributes = True
```

7. **Protect routes - Update existing routes**:
```python
# Example: app/routes/organizations.py
from app.core.deps import get_current_active_user
from app.models.user import User

@router.post("/", response_model=OrgSchema, status_code=status.HTTP_201_CREATED)
def create_organization(
    organization: OrganizationCreate,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)  # ADD THIS
):
    """Create a new organization"""
    org = Organization(**organization.model_dump())
    db.add(org)
    db.commit()
    db.refresh(org)
    return org
```

8. **Update `app/main.py`**:
```python
from app.routes.auth import router as auth_router

# Add before other routers
app.include_router(auth_router, prefix=settings.API_V1_PREFIX)
```

9. **Create database migration for users table**:
```sql
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE NOT NULL,
    hashed_password VARCHAR(255) NOT NULL,
    full_name VARCHAR(255),
    is_active BOOLEAN DEFAULT true,
    is_superuser BOOLEAN DEFAULT false,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_users_email ON users(email);
```

**Files to create**:
- `app/models/user.py`
- `app/core/security.py`
- `app/core/deps.py`
- `app/core/__init__.py`
- `app/routes/auth.py`
- `app/schemas/auth.py`

**Files to modify**:
- `app/config.py`
- `app/main.py`
- All route files (add authentication)
- `requirements.txt`

---

### Priority 1.4: Update CORS Configuration
**Status**: HIGH
**Time**: 30 minutes

**Current Issue**: CORS allows all methods/headers from hardcoded origins

**Update `app/main.py`**:
```python
from app.config import settings

app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.ALLOWED_ORIGINS,  # From config
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "PATCH"],  # Explicit methods
    allow_headers=["Authorization", "Content-Type"],  # Explicit headers
)
```

---

### Priority 1.5: Add Input Validation
**Status**: HIGH
**Time**: 2-3 hours

**Implementation**: Add Pydantic validators to schemas

**Example - Update `app/schemas/opportunity.py`**:
```python
from pydantic import BaseModel, Field, field_validator
from decimal import Decimal
from datetime import date

class OpportunityCreate(BaseModel):
    solicitation_number: str = Field(..., min_length=1, max_length=100)
    title: str = Field(..., min_length=1, max_length=500)
    mbe_goal: Decimal = Field(..., ge=0, le=100, description="MBE goal percentage (0-100)")
    vsbe_goal: Decimal = Field(..., ge=0, le=100, description="VSBE goal percentage (0-100)")
    total_value: Decimal = Field(..., gt=0, description="Total contract value must be positive")

    @field_validator('due_date')
    def due_date_must_be_future(cls, v):
        if v and v < date.today():
            raise ValueError('Due date must be in the future')
        return v

    @field_validator('naics_codes')
    def validate_naics_codes(cls, v):
        if v:
            for code in v:
                if not code.isdigit() or len(code) != 6:
                    raise ValueError(f'Invalid NAICS code: {code}. Must be 6 digits.')
        return v
```

**Apply to all schemas**:
- `app/schemas/bid.py`
- `app/schemas/subcontractor.py`
- `app/schemas/subcontractor_directory.py`
- `app/schemas/pre_bid_assessment.py`

---

## Phase 2: Database Optimization (Week 2) üìä

### Priority 2.1: Set Up Alembic for Database Migrations
**Time**: 3-4 hours

**Installation**:
```bash
pip install alembic==1.13.0
```

**Setup Steps**:

1. **Initialize Alembic**:
```bash
alembic init alembic
```

2. **Configure `alembic.ini`**:
```ini
# Change this line
sqlalchemy.url = driver://user:pass@localhost/dbname

# To this (use env var)
# sqlalchemy.url =
```

3. **Update `alembic/env.py`**:
```python
from app.config import settings
from app.database import Base
from app.models import *  # Import all models

# Set target metadata
target_metadata = Base.metadata

def get_url():
    return settings.DATABASE_URL

config.set_main_option("sqlalchemy.url", get_url())
```

4. **Create initial migration**:
```bash
alembic revision --autogenerate -m "Initial migration with all tables"
alembic upgrade head
```

5. **Add migration for indexes**:
```bash
alembic revision -m "Add performance indexes"
```

Edit the migration file:
```python
def upgrade():
    # Opportunities indexes
    op.create_index('idx_opportunities_naics', 'opportunities', ['naics_codes'], postgresql_using='gin')
    op.create_index('idx_opportunities_due_date', 'opportunities', ['due_date'])
    op.create_index('idx_opportunities_active', 'opportunities', ['is_active'])
    op.create_index('idx_opportunities_jurisdiction', 'opportunities', ['jurisdiction_id'])

    # Subcontractor directory indexes
    op.create_index('idx_directory_naics', 'subcontractor_directory', ['naics_codes'], postgresql_using='gin')
    op.create_index('idx_directory_jurisdictions', 'subcontractor_directory', ['jurisdiction_codes'], postgresql_using='gin')
    op.create_index('idx_directory_certifications', 'subcontractor_directory', ['certifications'], postgresql_using='gin')
    op.create_index('idx_directory_rating', 'subcontractor_directory', ['rating'])

    # Assessment indexes
    op.create_index('idx_assessments_org', 'pre_bid_assessments', ['organization_id'])
    op.create_index('idx_assessments_opp', 'pre_bid_assessments', ['opportunity_id'])
    op.create_index('idx_assessments_date', 'pre_bid_assessments', ['assessed_at'])

    # Outreach indexes
    op.create_index('idx_outreach_org', 'subcontractor_outreach', ['organization_id'])
    op.create_index('idx_outreach_opp', 'subcontractor_outreach', ['opportunity_id'])
    op.create_index('idx_outreach_sub', 'subcontractor_outreach', ['subcontractor_id'])
```

6. **Apply migration**:
```bash
alembic upgrade head
```

---

### Priority 2.2: Add Database Constraints
**Time**: 2 hours

**Create migration**:
```bash
alembic revision -m "Add database constraints"
```

**Migration content**:
```python
def upgrade():
    # Check constraints for percentages
    op.create_check_constraint(
        'chk_mbe_goal_range',
        'opportunities',
        'mbe_goal >= 0 AND mbe_goal <= 100'
    )

    op.create_check_constraint(
        'chk_vsbe_goal_range',
        'opportunities',
        'vsbe_goal >= 0 AND vsbe_goal <= 100'
    )

    op.create_check_constraint(
        'chk_total_value_positive',
        'opportunities',
        'total_value > 0'
    )

    op.create_check_constraint(
        'chk_rating_range',
        'subcontractor_directory',
        'rating >= 0 AND rating <= 5'
    )

    op.create_check_constraint(
        'chk_risk_score_range',
        'pre_bid_assessments',
        'overall_risk_score >= 0 AND overall_risk_score <= 100'
    )
```

---

### Priority 2.3: Optimize Database Connection
**Time**: 1 hour

**Update `app/database.py`**:
```python
from sqlalchemy import create_engine, event
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from sqlalchemy.pool import QueuePool
from app.config import settings

# Create engine with connection pooling
engine = create_engine(
    settings.DATABASE_URL,
    poolclass=QueuePool,
    pool_size=settings.DATABASE_POOL_SIZE,  # 5 default
    max_overflow=settings.DATABASE_MAX_OVERFLOW,  # 10 default
    pool_pre_ping=True,  # Verify connections before using
    pool_recycle=3600,  # Recycle connections after 1 hour
    echo=settings.DEBUG,  # SQL logging in debug mode
)

# Add connection event listeners for better logging
@event.listens_for(engine, "connect")
def receive_connect(dbapi_conn, connection_record):
    if settings.DEBUG:
        print("Database connection established")

SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()

def get_db():
    """Dependency to get database session with proper cleanup"""
    db = SessionLocal()
    try:
        yield db
    except Exception as e:
        db.rollback()  # Rollback on error
        raise
    finally:
        db.close()
```

---

### Priority 2.4: Fix Deprecated datetime.utcnow
**Time**: 30 minutes

**Find and replace across all model files**:
```python
# OLD (deprecated in Python 3.12+)
from datetime import datetime
created_at = Column(DateTime, default=datetime.utcnow)

# NEW
from datetime import datetime, timezone
created_at = Column(DateTime(timezone=True), default=lambda: datetime.now(timezone.utc))
```

**Files to update**:
- `app/models/pre_bid_assessment.py`
- `app/models/subcontractor_directory.py`
- `app/models/subcontractor_outreach.py`
- Any other models with timestamps

---

## Phase 3: Testing Infrastructure (Week 2-3) üß™

### Priority 3.1: Set Up Testing Framework
**Time**: 4-6 hours

**Install dependencies**:
```bash
pip install pytest==7.4.3
pip install pytest-asyncio==0.21.1
pip install httpx==0.25.1
pip install pytest-cov==4.1.0
pip install faker==20.1.0
```

**Create test structure**:
```
tests/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ conftest.py              # Shared fixtures
‚îú‚îÄ‚îÄ test_config.py           # Configuration tests
‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ test_models.py
‚îÇ   ‚îú‚îÄ‚îÄ test_services.py
‚îÇ   ‚îî‚îÄ‚îÄ test_utils.py
‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ test_api_auth.py
‚îÇ   ‚îú‚îÄ‚îÄ test_api_organizations.py
‚îÇ   ‚îú‚îÄ‚îÄ test_api_opportunities.py
‚îÇ   ‚îú‚îÄ‚îÄ test_api_assessments.py
‚îÇ   ‚îî‚îÄ‚îÄ test_database.py
‚îî‚îÄ‚îÄ fixtures/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îî‚îÄ‚îÄ sample_data.py
```

**Create `tests/conftest.py`**:
```python
import pytest
from fastapi.testclient import TestClient
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from sqlalchemy.pool import StaticPool

from app.main import app
from app.database import Base, get_db
from app.config import settings

# Test database (in-memory SQLite)
SQLALCHEMY_TEST_DATABASE_URL = "sqlite:///:memory:"

@pytest.fixture(scope="function")
def test_db():
    """Create a fresh database for each test"""
    engine = create_engine(
        SQLALCHEMY_TEST_DATABASE_URL,
        connect_args={"check_same_thread": False},
        poolclass=StaticPool,
    )
    TestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

    Base.metadata.create_all(bind=engine)

    db = TestingSessionLocal()
    try:
        yield db
    finally:
        db.close()
        Base.metadata.drop_all(bind=engine)

@pytest.fixture(scope="function")
def client(test_db):
    """Create test client with test database"""
    def override_get_db():
        try:
            yield test_db
        finally:
            pass

    app.dependency_overrides[get_db] = override_get_db

    with TestClient(app) as test_client:
        yield test_client

    app.dependency_overrides.clear()

@pytest.fixture
def auth_headers(client):
    """Create authenticated user and return headers"""
    # Register user
    client.post(
        f"{settings.API_V1_PREFIX}/auth/register",
        json={
            "email": "test@example.com",
            "password": "testpass123",
            "full_name": "Test User"
        }
    )

    # Login
    response = client.post(
        f"{settings.API_V1_PREFIX}/auth/login",
        data={
            "username": "test@example.com",
            "password": "testpass123"
        }
    )
    token = response.json()["access_token"]
    return {"Authorization": f"Bearer {token}"}
```

**Create `tests/integration/test_api_organizations.py`**:
```python
import pytest
from app.config import settings

def test_create_organization(client, auth_headers):
    """Test creating a new organization"""
    response = client.post(
        f"{settings.API_V1_PREFIX}/organizations",
        json={"name": "Test Construction Inc."},
        headers=auth_headers
    )
    assert response.status_code == 201
    data = response.json()
    assert data["name"] == "Test Construction Inc."
    assert "id" in data

def test_list_organizations(client, auth_headers):
    """Test listing organizations"""
    # Create a couple organizations
    client.post(
        f"{settings.API_V1_PREFIX}/organizations",
        json={"name": "Org 1"},
        headers=auth_headers
    )
    client.post(
        f"{settings.API_V1_PREFIX}/organizations",
        json={"name": "Org 2"},
        headers=auth_headers
    )

    # List them
    response = client.get(
        f"{settings.API_V1_PREFIX}/organizations",
        headers=auth_headers
    )
    assert response.status_code == 200
    data = response.json()
    assert len(data) == 2

def test_unauthorized_access(client):
    """Test that endpoints require authentication"""
    response = client.get(f"{settings.API_V1_PREFIX}/organizations")
    assert response.status_code == 401
```

**Create `tests/unit/test_services.py`**:
```python
import pytest
from decimal import Decimal
from datetime import date, timedelta
from app.services.pre_bid_assessment_service import PreBidAssessmentService

def test_risk_scoring_algorithm(test_db):
    """Test risk scoring logic"""
    service = PreBidAssessmentService(test_db)
    # Add tests for risk calculation logic
    # This ensures business rules are correct
```

**Run tests**:
```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=app --cov-report=html

# Run specific test file
pytest tests/integration/test_api_organizations.py

# Run with verbose output
pytest -v
```

**Add to `requirements.txt`**:
```
pytest==7.4.3
pytest-asyncio==0.21.1
pytest-cov==4.1.0
httpx==0.25.1
faker==20.1.0
```

---

## Phase 4: Operational Readiness (Week 3) üîß

### Priority 4.1: Add Structured Logging
**Time**: 2-3 hours

**Install**:
```bash
pip install python-json-logger==2.0.7
```

**Create `app/core/logging.py`**:
```python
import logging
import sys
from pythonjsonlogger import jsonlogger
from app.config import settings

def setup_logging():
    """Configure structured logging"""
    log_handler = logging.StreamHandler(sys.stdout)

    formatter = jsonlogger.JsonFormatter(
        '%(asctime)s %(name)s %(levelname)s %(message)s',
        rename_fields={
            'asctime': 'timestamp',
            'levelname': 'level',
            'name': 'logger'
        }
    )

    log_handler.setFormatter(formatter)

    logger = logging.getLogger()
    logger.addHandler(log_handler)
    logger.setLevel(logging.DEBUG if settings.DEBUG else logging.INFO)

    # Suppress noisy loggers
    logging.getLogger("uvicorn.access").setLevel(logging.WARNING)

    return logger

logger = setup_logging()
```

**Use in services**:
```python
from app.core.logging import logger

class PreBidAssessmentService:
    def perform_assessment(self, request):
        logger.info(
            "Starting pre-bid assessment",
            extra={
                "opportunity_id": str(request.opportunity_id),
                "organization_id": str(request.organization_id)
            }
        )
        # ... rest of code
```

**Add request logging middleware in `app/main.py`**:
```python
import time
from app.core.logging import logger

@app.middleware("http")
async def log_requests(request, call_next):
    start_time = time.time()

    response = await call_next(request)

    process_time = time.time() - start_time
    logger.info(
        "Request completed",
        extra={
            "method": request.method,
            "url": str(request.url),
            "status_code": response.status_code,
            "process_time": round(process_time, 3)
        }
    )

    return response
```

---

### Priority 4.2: Add Rate Limiting
**Time**: 2 hours

**Install**:
```bash
pip install slowapi==0.1.9
```

**Create `app/core/rate_limit.py`**:
```python
from slowapi import Limiter
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)
```

**Update `app/main.py`**:
```python
from slowapi import _rate_limit_exceeded_handler
from slowapi.errors import RateLimitExceeded
from app.core.rate_limit import limiter

app = FastAPI(...)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)
```

**Add to routes**:
```python
from app.core.rate_limit import limiter

@router.post("/", response_model=OrgSchema)
@limiter.limit("10/minute")  # 10 requests per minute
def create_organization(request: Request, ...):
    ...
```

---

### Priority 4.3: Add Health Checks
**Time**: 1 hour

**Update health endpoint in `app/main.py`**:
```python
from sqlalchemy import text

@app.get("/health")
def health_check(db: Session = Depends(get_db)):
    """Comprehensive health check"""
    health_status = {
        "status": "healthy",
        "service": settings.PROJECT_NAME,
        "version": "2.0",
        "checks": {}
    }

    # Database check
    try:
        db.execute(text("SELECT 1"))
        health_status["checks"]["database"] = "healthy"
    except Exception as e:
        health_status["status"] = "unhealthy"
        health_status["checks"]["database"] = f"unhealthy: {str(e)}"

    return health_status

@app.get("/health/ready")
def readiness_check():
    """Kubernetes readiness probe"""
    return {"status": "ready"}

@app.get("/health/live")
def liveness_check():
    """Kubernetes liveness probe"""
    return {"status": "alive"}
```

---

### Priority 4.4: Add Redis Caching (Optional but Recommended)
**Time**: 3-4 hours

**Install**:
```bash
pip install redis==5.0.1
pip install hiredis==2.2.3  # C parser for better performance
```

**Add to `.env`**:
```env
REDIS_URL=redis://localhost:6379/0
CACHE_TTL=300  # 5 minutes default
```

**Create `app/core/cache.py`**:
```python
import redis
import json
from typing import Optional
from app.config import settings

class RedisCache:
    def __init__(self):
        self.redis_client = redis.from_url(
            settings.REDIS_URL,
            decode_responses=True
        )

    def get(self, key: str) -> Optional[dict]:
        """Get value from cache"""
        data = self.redis_client.get(key)
        return json.loads(data) if data else None

    def set(self, key: str, value: dict, ttl: int = 300):
        """Set value in cache with TTL"""
        self.redis_client.setex(
            key,
            ttl,
            json.dumps(value, default=str)
        )

    def delete(self, key: str):
        """Delete key from cache"""
        self.redis_client.delete(key)

    def clear_pattern(self, pattern: str):
        """Clear all keys matching pattern"""
        for key in self.redis_client.scan_iter(match=pattern):
            self.redis_client.delete(key)

cache = RedisCache()
```

**Use in services**:
```python
from app.core.cache import cache

class JurisdictionService:
    def get_jurisdiction_by_code(self, code: str):
        # Try cache first
        cache_key = f"jurisdiction:{code}"
        cached = cache.get(cache_key)
        if cached:
            return cached

        # Fetch from database
        jurisdiction = self.db.query(Jurisdiction).filter(...).first()

        # Cache result
        if jurisdiction:
            cache.set(cache_key, jurisdiction.to_dict(), ttl=3600)

        return jurisdiction
```

---

## Phase 5: Advanced Features (Week 4) üöÄ

### Priority 5.1: Add Background Job Processing
**Time**: 4-6 hours

**Install Celery**:
```bash
pip install celery[redis]==5.3.4
```

**Create `app/tasks/__init__.py`**:
```python
from celery import Celery
from app.config import settings

celery_app = Celery(
    "complyform",
    broker=settings.REDIS_URL,
    backend=settings.REDIS_URL
)

celery_app.conf.update(
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    timezone='UTC',
    enable_utc=True,
)
```

**Create background tasks in `app/tasks/assessment_tasks.py`**:
```python
from app.tasks import celery_app
from app.database import SessionLocal
from app.services import PreBidAssessmentService

@celery_app.task(name="perform_bulk_assessment")
def perform_bulk_assessment(opportunity_ids: list, organization_id: str):
    """Perform assessments for multiple opportunities in background"""
    db = SessionLocal()
    try:
        service = PreBidAssessmentService(db)
        results = []
        for opp_id in opportunity_ids:
            result = service.perform_assessment(...)
            results.append(result)
        return results
    finally:
        db.close()
```

**Run Celery worker**:
```bash
celery -A app.tasks worker --loglevel=info
```

---

### Priority 5.2: Add API Documentation Enhancements
**Time**: 2 hours

**Update `app/main.py`**:
```python
app = FastAPI(
    title="ComplyFormAI API",
    description="""
    ## ComplyFormAI - Compliance-First Platform

    This API provides comprehensive compliance management for construction bidding.

    ### Features
    - üèõÔ∏è Multi-jurisdiction support (MD, DC, extensible)
    - üìä Pre-bid risk assessment with intelligent scoring
    - üë• Subcontractor directory and matching
    - üîî Opportunity alerts and tracking
    - üìß Subcontractor outreach management
    - ‚úÖ Cross-form validation

    ### Authentication
    Most endpoints require authentication. Use `/api/v1/auth/login` to get a token.
    """,
    version="2.0.0",
    contact={
        "name": "ComplyFormAI Support",
        "email": "support@complyformai.com"
    },
    license_info={
        "name": "MIT",
    },
    docs_url="/docs",
    redoc_url="/redoc",
    openapi_tags=[
        {"name": "authentication", "description": "User authentication and registration"},
        {"name": "organizations", "description": "Organization management"},
        {"name": "opportunities", "description": "Procurement opportunities"},
        {"name": "pre-bid-assessments", "description": "Bid/no-bid intelligence"},
        {"name": "directory", "description": "Subcontractor directory"},
        {"name": "outreach", "description": "Outreach tracking"},
    ]
)
```

---

### Priority 5.3: Add Monitoring & Metrics
**Time**: 3-4 hours

**Install Prometheus client**:
```bash
pip install prometheus-fastapi-instrumentator==6.1.0
```

**Update `app/main.py`**:
```python
from prometheus_fastapi_instrumentator import Instrumentator

# Add after app creation
Instrumentator().instrument(app).expose(app)
```

**Access metrics**:
```
http://localhost:8000/metrics
```

---

## Phase 6: Documentation & Deployment (Week 4) üìö

### Priority 6.1: Update Documentation
**Time**: 2-3 hours

**Update README.md** with:
- New authentication instructions
- Environment variable configuration
- Testing instructions
- Deployment guide

**Create CONTRIBUTING.md**:
- Code style guide
- Pull request process
- Testing requirements

**Create DEPLOYMENT.md**:
- Production checklist
- Environment setup
- Docker deployment
- Database migration process

---

### Priority 6.2: Docker Setup
**Time**: 2-3 hours

**Create `Dockerfile`**:
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application
COPY ./app ./app
COPY ./alembic ./alembic
COPY ./alembic.ini .

# Create non-root user
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

EXPOSE 8000

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**Create `docker-compose.yml`**:
```yaml
version: '3.8'

services:
  db:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: ComplyFormAI
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      DATABASE_URL: postgresql://postgres:${DB_PASSWORD}@db:5432/ComplyFormAI
      REDIS_URL: redis://redis:6379/0
      DEBUG: "false"
      SECRET_KEY: ${SECRET_KEY}
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    command: >
      sh -c "alembic upgrade head &&
             uvicorn app.main:app --host 0.0.0.0 --port 8000"

  celery_worker:
    build: .
    environment:
      DATABASE_URL: postgresql://postgres:${DB_PASSWORD}@db:5432/ComplyFormAI
      REDIS_URL: redis://redis:6379/0
    depends_on:
      - db
      - redis
    command: celery -A app.tasks worker --loglevel=info

volumes:
  postgres_data:
```

**Run with Docker**:
```bash
docker-compose up -d
```

---

## Summary Timeline

| Phase | Duration | Priority | Key Deliverables |
|-------|----------|----------|------------------|
| **Phase 1** | Week 1 | CRITICAL | Security fixes, authentication, validation |
| **Phase 2** | Week 2 | HIGH | Database optimization, migrations, constraints |
| **Phase 3** | Week 2-3 | HIGH | Testing framework, unit & integration tests |
| **Phase 4** | Week 3 | MEDIUM | Logging, rate limiting, caching, health checks |
| **Phase 5** | Week 4 | LOW | Background jobs, enhanced docs, monitoring |
| **Phase 6** | Week 4 | MEDIUM | Docker, deployment guide, production docs |

---

## Quick Start Guide

### Immediate Fix for 404 Error

**Problem**: Accessing `http://localhost:8000/api/vi/organizations` returns 404

**Solution**: Use correct URL: `http://localhost:8000/api/v1/organizations`

**Test all endpoints**:
```bash
# Health check
curl http://localhost:8000/health

# List organizations (will work after authentication is added)
curl http://localhost:8000/api/v1/organizations

# View interactive docs
open http://localhost:8000/docs
```

---

## Next Steps

1. ‚úÖ **Fix the 404 error** - Use correct URL path
2. ‚ö†Ô∏è **Week 1**: Implement Phase 1 (Security fixes)
3. üìä **Week 2**: Implement Phase 2 & 3 (Database & Testing)
4. üîß **Week 3**: Implement Phase 4 (Operations)
5. üöÄ **Week 4**: Implement Phase 5 & 6 (Advanced features)

---

## Questions or Issues?

If you encounter any issues during implementation:
1. Check the logs: Look for error messages
2. Verify environment variables are set correctly
3. Ensure database is running and accessible
4. Check that all dependencies are installed

Would you like me to start implementing any specific phase?
